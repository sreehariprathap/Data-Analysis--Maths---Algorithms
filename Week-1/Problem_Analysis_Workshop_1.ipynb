{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Mathematics, Algorithms and Modeling\n",
    "\n",
    "## Team Information - Problem Analysis Workshop 1\n",
    "\n",
    "**Team Members**\n",
    "\n",
    "Name: Ayush Patel  \n",
    "Student Number: 9033358\n",
    "\n",
    "Name: Nikhil Shankar  \n",
    "Student Number: 9026254\n",
    "\n",
    "Name: Sreehari Prathap  \n",
    "Student Number: 8903199\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge \n",
    "\n",
    "### Field Of Inquiry - Talent Acquisition\n",
    "#### Amazon Recruitment Automation And Gender Bias Case Study\n",
    "\n",
    "In 2015 Amazon found out a serious issue with the automated tool used in recruitment. The tool was designed to filter and rank the resumes based on job requirements. To train their model Amazon relied on previous decade data consisting of the resumes that were submitted, the corresponding job descriptions and the subset of resumes that were finally hired. The model was giving undue advantage for male applicants over females especially for the technical positions due to the inherent bias historically. This resulted in the model giving higher priority for resumes in the male perspective than the female one.\n",
    "\n",
    "#### How can we track it?\n",
    "In this context, tracking the bias in the automated recruitment tool is crucial. Monitoring its performance and ensuring that it doesn't favor male applicants over female applicants or any other demographic group is essential. Tracking would involve evaluating the modelâ€™s output, analyzing the impact of changes made to the model, and ensuring fairness across different gender, racial, and socioeconomic groups.\n",
    "\n",
    "**References**\n",
    "- *[Reuters]\n",
    "(https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G/)*\n",
    "- *[Global Headcount]\n",
    "(https://fingfx.thomsonreuters.com/gfx/rngs/AMAZON.COM-JOBS-AUTOMATION/010080Q91F6/index.html)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install and Configure the IDE (e.g., Jupyter Notebook and VS Code)\n",
    "- Install Anaconda (for Jupyter Notebook) and Visual Studio Code (VS Code).\n",
    "  - Anaconda: Visit [anaconda.com](https://www.anaconda.com/products/individual) and download the appropriate installer for your operating system.\n",
    "  - VS Code: Download and install from [Visual Studio Code](https://code.visualstudio.com/).\n",
    "- Install Pandas Library\n",
    "  - Open the terminal and run the following command: `pip install pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Downloading the Dataset\n",
    "We are using the Utrecht Fairness Recruitment dataset from [Kaggle], which can be downloaded directly via the link:\n",
    "- URL: [https://www.kaggle.com/datasets/ictinstitute/utrecht-fairness-recruitment-dataset]\n",
    "\n",
    "### Displaying the csv file using python\n",
    "Import panda to read the dataset in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file using panda\n",
    "The parameter \"**nrows**\" is used to read only the first n rows since this is a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"recruitmentdataset-2022-1.3.csv\"\n",
    "df = pd.read_csv(file, nrows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 columns in the csv and for display purpose we use only 6 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id  gender  age  ... ind-degree company  decision\n",
      "0  x8011e  female   24  ...        phd       A      True\n",
      "1  x6077a    male   26  ...   bachelor       A     False\n",
      "2  x6006e  female   23  ...     master       A     False\n",
      "3  x2173b    male   24  ...     master       A      True\n",
      "4  x6241a  female   26  ...     master       A      True\n",
      "5  x9063d  female   26  ...   bachelor       A      True\n",
      "6  x5785d  female   27  ...   bachelor       A     False\n",
      "7  x8767c  female   22  ...     master       A      True\n",
      "8  x6541b  female   28  ...   bachelor       A     False\n",
      "9  x3890b    male   24  ...     master       A      True\n",
      "\n",
      "[10 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = 6\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Data Cleansing\n",
    "\n",
    "### Data Cleansing Process for User Data (Talent Acquisition) from a CSV File\n",
    "\n",
    "Before analyzing user data for talent acquisition, it is essential to clean the data for accuracy and consistency. The key actions for data cleansing include:\n",
    "\n",
    "1. **Import the Data**: Load the CSV file containing user information into your data analysis tool (e.g., Excel, Python, or SQL).\n",
    "\n",
    "2. **Merge Data Sets**: If user data comes from multiple sources, ensure it's combined into a consistent format for further analysis.\n",
    "\n",
    "3. **Remove Duplicates**: Identify and remove duplicate entries based on unique identifiers like email addresses or phone numbers.\n",
    "\n",
    "4. **Standardize Data**: Clean up inconsistencies like extra spaces, incorrect capitalization, or formatting issues (e.g., \"Mr.\" instead of \"mister\").\n",
    "\n",
    "5. **Handle Missing Data**: Fill in missing values where possible or remove rows with incomplete critical data fields.\n",
    "\n",
    "6. **Validate Key Fields**: Ensure fields like phone numbers, emails, and addresses follow a standard format for consistency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SYSTOLIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  TotalSteps  Calories  TotalSleepRecords  TotalMinutesAsleep\n",
      "30  2016-05-12           0         0                NaN                 NaN\n",
      "99  2016-04-19         197      1366                NaN                 NaN\n",
      "71  2016-04-21        1223      2140                NaN                 NaN\n",
      "91  2016-05-11        1329      1276                NaN                 NaN\n",
      "34  2016-04-15        1510      1344                NaN                 NaN\n",
      "..         ...         ...       ...                ...                 ...\n",
      "13  2016-04-25       15355      2013                1.0               277.0\n",
      "7   2016-04-19       15506      2035                1.0               304.0\n",
      "15  2016-04-27       18134      2159                NaN                 NaN\n",
      "80  2016-04-30       18213      3846                1.0               124.0\n",
      "50  2016-05-01       36019      2690                NaN                 NaN\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"Daily_merged.csv\"\n",
    "df_unfiltered = pd.read_csv(file, nrows=100)\n",
    "df = df_unfiltered.dropna(axis=1, how='all')\n",
    "\n",
    "columns_of_interest = ['time', 'TotalSteps', 'Calories','TotalSleepRecords','TotalMinutesAsleep']  # Replace with your actual column names\n",
    "df_selected = df[columns_of_interest]\n",
    "\n",
    "# Sort by one of the columns in ascending order\n",
    "df_sorted = df_selected.sort_values(by='TotalSteps', ascending=True)\n",
    "\n",
    "\n",
    "df_sorted_desc = df_selected.sort_values(by='TotalSteps', ascending=False)\n",
    "\n",
    "pd.options.display.max_columns = 6\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  TotalSteps  Calories  TotalSleepRecords  TotalMinutesAsleep\n",
      "50  2016-05-01       36019      2690                NaN                 NaN\n",
      "80  2016-04-30       18213      3846                1.0               124.0\n",
      "15  2016-04-27       18134      2159                NaN                 NaN\n",
      "7   2016-04-19       15506      2035                1.0               304.0\n",
      "13  2016-04-25       15355      2013                1.0               277.0\n",
      "..         ...         ...       ...                ...                 ...\n",
      "34  2016-04-15        1510      1344                NaN                 NaN\n",
      "91  2016-05-11        1329      1276                NaN                 NaN\n",
      "71  2016-04-21        1223      2140                NaN                 NaN\n",
      "99  2016-04-19         197      1366                NaN                 NaN\n",
      "30  2016-05-12           0         0                NaN                 NaN\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_sorted_desc = df_selected.sort_values(by='TotalSteps', ascending=False)\n",
    "print(df_sorted_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          time  TotalSteps  Calories  TotalSleepRecords  TotalMinutesAsleep\n",
      "30  2016-05-12           0         0                NaN                 NaN\n",
      "61  2016-05-12        2971      1002                NaN                 NaN\n",
      "91  2016-05-11        1329      1276                NaN                 NaN\n",
      "58  2016-05-09        1732      1328                NaN                 NaN\n",
      "52  2016-05-03        2100      1334                NaN                 NaN\n",
      "..         ...         ...       ...                ...                 ...\n",
      "83  2016-05-03       12850      3324                NaN                 NaN\n",
      "86  2016-05-06        9787      3328                NaN                 NaN\n",
      "87  2016-05-07       13372      3404                NaN                 NaN\n",
      "66  2016-04-16       15300      3493                NaN                 NaN\n",
      "80  2016-04-30       18213      3846                1.0               124.0\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def sort_data(df, column_name, isAscending):\n",
    "    return df.sort_values(by=column_name, ascending=isAscending)\n",
    "\n",
    "\n",
    "sortedBasedOnCalories = sort_data(df_sorted, 'Calories', 1)\n",
    "print(sortedBasedOnCalories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classical_ml_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
